---
title: "Data modeling"
author: "Ich"
date: "3/9/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---



```{r knitr-setup}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  out.width = "70%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp =  0.4,  #0.618,  # 1 / phi
  fig.show = "hold",
  size = "tiny"
)

```



# Load packages


```{r}
library(sjmisc)
library(viridis)
library(pradadata)  # elec data
library(tidyverse)
library(knitr)
library(tidylog)

library(rethinking)  # Bayes modeling

```


# Load data

Raw data:

```{r}
d <- read_csv("objects/d_prepared.csv")
d <- as.data.frame(d)
```


And now the data frame with the reduced sample size of n=79,
because that's the number of complete rows for the modeling variables. 

However, we let all variables remain in the dataframe for computing prediction error later on.

```{r}
d79 <- d %>% 
  drop_na(one_of(c(consumer_types, standard_model_vars))) %>% 
  as.data.frame()

dim(d)
dim(d79)
```


objects from models:

```{r}
load("objects/models.Rda")
```


# Helper stuff

```{r}
standard_model_vars <- c("afd_prop", "for_prop_z", "unemp_prop_z", "east")
consumer_types <- c("enjoyer", "harmony_seeker",
                    "hedonist", "self_determined",
                    "appreciater", "type_unknown",
                    "conformist", "responsibility_denier")
```



```{r my-traceplot}
my_traceplot <- function(model) {
  rstan::traceplot(model@stanfit, pars=names(model@start[[1]]))
}
```


# Modeling

## model output list

I use this list to store the model outputs.

```{r}
if (!(exists("models"))) models <- list()
```


## Null models


### Normal null model (model 00)


```{r m0, eval = TRUE, results = "hide"}
d_model <- d[, c("afd_prop"), drop = FALSE]
nrow(d_model)

m0 <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),    
    mu <- alpha,
    alpha ~ dnorm(0, 1),
    sigma ~ dnorm(0, 1)
  ),
  data = d_model,
  chains = 2
)
```



```{r}
precis(m0, depth = 2)
coeftab(m0)
my_traceplot(m0)
models[["m0"]] <-m0
```


### m0a: Normal null model (model 00) with reduced sample size

```{r m0a, eval = TRUE, results = "hide"}
d_model <- d79
nrow(d_model)

m0a <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),    
    mu <- alpha,
    alpha ~ dnorm(0, 1),
    sigma ~ dnorm(0, 1)
  ),
  data = d_model,
  chains = 2
)
```


```{r}
precis(m0a, depth = 2)
coeftab(m0a)
my_traceplot(m0a)
models[["m0a"]] <-m0a
WAIC(m0a)
```



### m0b: Normal null model (model 00) with reduced sample size, sigma as Cauchy

```{r m0b, eval = TRUE, results = "hide"}
d_model <- d %>% 
  select(one_of(c(consumer_types, standard_model_vars))) %>% 
  drop_na() %>% 
  as.data.frame()
nrow(d_model)

m0b <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),    
    mu <- alpha,
    alpha ~ dnorm(0, 1),
    sigma ~ dcauchy(0, 1)
  ),
  data = d_model,
  chains = 2
)
```


```{r}
precis(m0b, depth = 2)
coeftab(m0b)
my_traceplot(m0b)
models[["m0b"]] <-m0b
WAIC(m0b)
```






## One level models


### Model 01a: - 8 consumer vars + unemp-z + foreign-z, REDUCED sample size



```{r m1a, error = TRUE, results = "hide"}
d_model <- d %>% 
  select(one_of(c(consumer_types, standard_model_vars))) %>% 
  drop_na() %>% 
  as.data.frame()

class(d_model)
nrow(d_model)

m1a <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),
    mu <-  beta0[east] +  beta1*for_prop_z + beta2*unemp_prop_z + 
      beta3*enjoyer + beta4*harmony_seeker + beta5*self_determined +
      beta6*appreciater + beta7*conformist + beta8*type_unknown +
      beta9*responsibility_denier,
    beta0[east] ~ dnorm(0, 1),
    beta1 ~ dnorm(0, 1),
    beta2 ~ dnorm(0, 1),
    beta3 ~ dnorm(0, 1),   
    beta4 ~ dnorm(0, 1),    
    beta5 ~ dnorm(0, 1),    
    beta6 ~ dnorm(0, 1),
    beta7 ~ dnorm(0, 1),
    beta8 ~ dnorm(0, 1),
    beta9 ~ dnorm(0, 1),
    sigma ~ dnorm(0, 1)
  ),
  data = d_model,
  chains = 2,
  cores = 1
)
```

Check the results:

```{r}
my_traceplot(m1a)
precis(m1a, depth = 2)
models[["m1a"]] <- m1a
WAIC(m1a)
```



### M01b: sigma cauchy distributed

Now with sigma Cauchy distributed:

```{r m1b, error = TRUE, results = "hide"}
d_model <- d %>% 
  select(one_of(c(consumer_types, standard_model_vars))) %>% 
  drop_na() %>% 
  as.data.frame()

class(d_model)
nrow(d_model)

m1b <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),
    mu <-  beta0[east] +  beta1*for_prop_z + beta2*unemp_prop_z + 
      beta3*enjoyer + beta4*harmony_seeker + beta5*self_determined +
      beta6*appreciater + beta7*conformist + beta8*type_unknown +
      beta9*responsibility_denier,
    beta0[east] ~ dnorm(0, 1),
    beta1 ~ dnorm(0, 1),
    beta2 ~ dnorm(0, 1),
    beta3 ~ dnorm(0, 1),   
    beta4 ~ dnorm(0, 1),    
    beta5 ~ dnorm(0, 1),    
    beta6 ~ dnorm(0, 1),
    beta7 ~ dnorm(0, 1),
    beta8 ~ dnorm(0, 1),
    beta9 ~ dnorm(0, 1),
    sigma ~ dcauchy(0, 1)
  ),
  data = d_model,
  chains = 2,
  cores = 1
)
```

Check the results:

```{r}
my_traceplot(m1b)
precis(m1b, depth = 2)
WAIC(m1b)
models[["m1b"]] <- m1b
```


### Model 02 -  unemp-z + foreign-z NO consumer vars



```{r m2, results = "hide"}
d_model <- d[, c("afd_prop", "for_prop_z", "unemp_prop_z")]
d_model <- as.data.frame(d_model)
d_model <- d %>% 
  select(one_of(c(consumer_types, standard_model_vars))) %>% 
  drop_na() %>% 
  as.data.frame()

nrow(d_model)


m2 <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),
    mu <- alpha +  beta1*for_prop_z + beta2*unemp_prop_z,
    alpha ~ dnorm(0, 1),
    beta1 ~ dnorm(0, 1),
    beta2 ~ dnorm(0, 1),
    sigma ~ dnorm(0, 1)
  ),
  data = d_model,
  chains = 2,
  cores = 2)
```



Check the results:

```{r}
my_traceplot(m2)
precis(m2, depth = 2)
models[["m2"]] <- m2
WAIC(m2)
```


### M02a - reduced sample size

Now with the reduced sample size:

```{r m2a, results = "hide"}
d_model <- d %>% 
  select(one_of(c(consumer_types, standard_model_vars))) %>% 
  drop_na() %>% 
  as.data.frame()

nrow(d_model)


m2a <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),
    mu <- alpha +  beta1*for_prop_z + beta2*unemp_prop_z,
    alpha ~ dnorm(0, 1),
    beta1 ~ dnorm(0, 1),
    beta2 ~ dnorm(0, 1),
    sigma ~ dnorm(0, 1)
  ),
  data = d_model,
  chains = 2,
  cores = 2)
```



Check the results:

```{r}
my_traceplot(m2a)
precis(m2a, depth = 2)
models[["m2a"]] <- m2a
WAIC(m2a)
```

### M02b - sigma Cauchy distributed



```{r m2b, results = "hide"}
d_model <- d %>% 
  select(one_of(c(consumer_types, standard_model_vars))) %>% 
  drop_na() %>% 
  as.data.frame()

nrow(d_model)


m2b <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),
    mu <- alpha +  beta1*for_prop_z + beta2*unemp_prop_z,
    alpha ~ dnorm(0, 1),
    beta1 ~ dnorm(0, 1),
    beta2 ~ dnorm(0, 1),
    sigma ~ dcauchy(0, 1)
  ),
  data = d_model,
  chains = 2,
  cores = 2)
```



Check the results:

```{r}
my_traceplot(m2b)
precis(m2b, depth = 2)
models[["m2b"]] <- m2b
WAIC(m2b)
```



## Multilevel (two levels)


### M03: east + for_prop-z + unemp_prop-z

```{r m3, eval = TRUE, results = "hide"}
d_model <- d[, c("afd_prop", "for_prop_z", "unemp_prop_z", "east")]
nrow(d_model)

m3 <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),    
    mu <- beta0[east] +  beta1*for_prop_z + beta2*unemp_prop_z,
    beta0[east] ~ dnorm(0, sigma2),
    sigma ~ dnorm(0, 1),
    beta1 ~ dnorm(0, 1),
    beta2 ~ dnorm(0, 1),
    sigma2 ~ dnorm(0, 1)
  ),
  data = d_model,
  chains = 2,
  cores = 2
)
```



```{r}
precis(m3, depth = 2)
coeftab(m3)
my_traceplot(m3)
models[["m3"]] <- m3
```

### M03a: east + for_prop-z + unemp_prop-z REDUCED sample size

```{r m3a, eval = TRUE, results = "hide"}
d_model <- d %>% 
  select(one_of(c(consumer_types, standard_model_vars))) %>% 
  drop_na() %>% 
  as.data.frame()

nrow(d_model)

m3a <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),    
    mu <- beta0[east] +  beta1*for_prop_z + beta2*unemp_prop_z,
    beta0[east] ~ dnorm(0, sigma2),
    sigma ~ dnorm(0, 1),
    beta1 ~ dnorm(0, 1),
    beta2 ~ dnorm(0, 1),
    sigma2 ~ dnorm(0, 1)
  ),
  data = d_model,
  chains = 2,
  cores = 2
)
```



```{r}
precis(m3a, depth = 2)
coeftab(m3a)
my_traceplot(m3a)
models[["m3a"]] <- m3a
WAIC(m3a)
```


### M03b: east + for_prop-z + unemp_prop-z REDUCED sample size, CAUCHY

```{r m3b, eval = TRUE, results = "hide"}
d_model <- d %>% 
  select(one_of(c(consumer_types, standard_model_vars))) %>% 
  drop_na() %>% 
  as.data.frame()

nrow(d_model)

m3b <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),    
    mu <- beta0[east] +  beta1*for_prop_z + beta2*unemp_prop_z,
    beta0[east] ~ dnorm(0, sigma2),
    sigma ~ dnorm(0, 1),
    beta1 ~ dnorm(0, 1),
    beta2 ~ dnorm(0, 1),
    sigma2 ~ dcauchy(0, 1)
  ),
  data = d_model,
  chains = 2,
  cores = 2
)
```



```{r}
precis(m3b, depth = 2)
coeftab(m3b)
my_traceplot(m3b)
models[["m3b"]] <- m3b
WAIC(m3b)
```





### M04: state + for_prop-z + unemp_prop-z

```{r m4, eval = TRUE, results = "hide"}
d_model <- d[, c("afd_prop", "for_prop_z", "unemp_prop_z", "state_id")]
nrow(d_model)

m4 <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),    
    mu <- beta0[state_id] +  beta1*for_prop_z + beta2*unemp_prop_z,
    beta0[state_id] ~ dnorm(0, sigma2),
    sigma ~ dnorm(0, 1),
    sigma2 ~ dnorm(0, 1),
    beta1 ~ dnorm(0, 1),
    beta2 ~ dnorm(0, 1)
  ),
  data = d_model,
  chains = 2,
  cores  = 2
)
```



```{r out.width="100%"}
precis(m4, depth = 2)
coeftab(m4)
my_traceplot(m4)
models[["m4"]] <- m4
```





### M04a: state + for_prop-z + unemp_prop-z, REDUCED sample size



```{r m4a, eval = TRUE, results = "hide"}
d_model <- d %>% 
  select(one_of(c(consumer_types, standard_model_vars, "state_id"))) %>% 
  drop_na() %>% 
  as.data.frame()

nrow(d_model)

m4a <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),    
    mu <- beta0[state_id] +  beta1*for_prop_z + beta2*unemp_prop_z,
    beta0[state_id] ~ dnorm(0, sigma2),
    sigma ~ dnorm(0, 1),
    sigma2 ~ dnorm(0, 1),
    beta1 ~ dnorm(0, 1),
    beta2 ~ dnorm(0, 1)
  ),
  data = d_model,
  chains = 2,
  cores  = 2
)
```



```{r out.width="100%"}
precis(m4a, depth = 2)
coeftab(m4a)
my_traceplot(m4a)
models[["m4a"]] <- m4a

```


### M04b: state + for_prop-z + unemp_prop-z, REDUCED sample size, Cauchy



```{r m4b, eval = TRUE, results = "hide"}
d_model <- d %>% 
  select(one_of(c(consumer_types, standard_model_vars, "state_id"))) %>% 
  drop_na() %>% 
  as.data.frame()

nrow(d_model)

m4b <- map2stan(
  alist(
    afd_prop ~ dnorm(mu, sigma),    
    mu <- beta0[state_id] +  beta1*for_prop_z + beta2*unemp_prop_z,
    beta0[state_id] ~ dnorm(0, sigma2),
    sigma ~ dnorm(0, 1),
    sigma2 ~ dnorm(0, 1),
    beta1 ~ dnorm(0, 1),
    beta2 ~ dcauchy(0, 1)
  ),
  data = d_model,
  chains = 2,
  cores  = 2
)
```



```{r out.width="100%"}
precis(m4b, depth = 2)
coeftab(m4b)
my_traceplot(m4b)
models[["m4b"]] <- m4b
```



# Check model object

```{r}
names(models)
```


# Model comparison

## Compare null models:

```{r}
compare_null_models <- compare( models[["m0a"]], models[["m0b"]])
compare_null_models
```


## Compare models of reduced sample size

```{r}
models79 <- list(models[["m0a"]], models[["m0b"]],
                 models[["m1a"]], models[["m1b"]],
                 models[["m2a"]], models[["m2b"]],
                 models[["m3a"]], models[["m3b"]],
                 models[["m4a"]], models[["m4b"]])

models79 <- models[c("m0a", "m0b",
                     "m1a", "m1b",
                     "m2a", "m2b",
                     "m3a", "m3b",
                     "m4a", "m4b")]

length(models79)

names(models79)

model_names <- names(models79)

``



```{r}
compare_reduced_sample <- compare(
                                              models[["m0a"]], models[["m0b"]],
                                              models[["m1a"]], models[["m1b"]],
                                              models[["m2a"]], models[["m2b"]],
                                              models[["m3a"]], models[["m3b"]],
                                              models[["m4a"]], models[["m4b"]])
compare_reduced_sample

```


# Get best model (Gaussian)

Which model ist best? Let's define the model with the lowest WAIC as best:

```{r}
compare_reduced_sample@output %>% 
  rownames_to_column(var = "model_name") %>%  
  slice(which.min(WAIC)) -> best_model
```

And now extract the name of the best model:

```{r}
best_model_name <-
  best_model %>%
  pull(model_name)

best_model_name

if (best_model_name == 'models[[\"m4a\"]]') best_model_name = "m4a"
best_model_name
```







# Computing prediction errors


Here's a function to compute the modeling error, defined as the absolute difference of the estimated model value (of afd proportion) minus the observed value (of afd proportion).


```{r fun-comp-err}
comp_error <- function(model, data, fun = mean) {
  posterior_per_person <- link(model)
  
  
  as_tibble(posterior_per_person) %>% 
    summarise_all(fun) %>% 
    gather() %>% 
    rename(estimate = value) %>% 
    mutate(afd_prop = data$afd_votes / data$votes_total,
           error = abs(estimate - afd_prop)) %>% 
    pull(error) -> error_vec
  
  return(error_vec)
}

```


Apply the function on all models:

```{r comp-all-model-errors, results = "hide"}
model_error <- lapply(models79, comp_error, data = d79)

model_error
```


Compute the median absolute error:


```{r md-abs-err, results = "hide"}
md_abs_error_all_models <- sapply(model_error, median) %>% unlist()
md_abs_error_all_models

```



Also, compute the IQR of the errors:

```{r iqr-abs-err, results = "hide"}
modell_error_IQR <- lapply(models79, comp_error, fun = IQR, data = d79)
modell_error_IQR
```







# Visualizing prediction error

Some preparation:

```{r prepare-error-data}
model_error %>% 
    as.data.frame() -> model_error_df


names(model_error_df) <- names(models79)

model_error_df %>% 
  mutate(afd_prop = d79$afd_prop,
         id = 1:nrow(model_error_df)) -> model_error_df


modell_error_IQR %>% 
  as.data.frame() -> model_error_IQR_df


names(model_error_IQR_df) <- names(models79)

model_error_IQR_df %>% 
  mutate(id = 1:nrow(model_error_IQR_df)) -> model_error_IQR_df

```



Convert to long version for plotting:

```{r convert-error-data}
model_error_IQR_df %>% 
  gather(key = model, value = iqr, -c(id)) %>% 
  mutate(stat = "IQR") -> model_error_IQR_df_long


model_error_df %>% 
  gather(key = model, value = error, -c(afd_prop, id)) %>% 
  mutate(stat = "median") -> model_error_df_long

model_error_df_long %>% 
  bind_rows(model_error_IQR_df_long) -> model_error_long


model_error_df_long %>% 
  left_join(model_error_IQR_df_long, by = c("id", "model")) %>% 
  select(-c(stat.x, stat.y)) -> model_error_md_iqr

glimpse(model_error_md_iqr)

```


Now plot:

```{r plot-model-error, out.width = "100%"}


as_tibble(md_abs_error_all_models) %>% 
  mutate(model = model_names,
         best_model = ifelse(model_names == best_model_name, TRUE, FALSE)) -> md_abs_error_all_models

glimpse(md_abs_error_all_models)

p_model_error_md_iqr <- model_error_md_iqr %>% 
  arrange(-error) %>% 
  ggplot(aes(x = id)) +
  facet_wrap(~model) +
  geom_hline(aes(yintercept = value), data = md_abs_error_all_models) +
    geom_errorbar(aes(ymin = error - (iqr/2),
                    ymax = error + (iqr/2)),
                alpha = .3,
                color = "gray40") +
  geom_point(aes(y = error), alpha = .1) +
  geom_label(aes(label = round(value, 3),
                 color = best_model), x = 1, y = .2, 
            data = md_abs_error_all_models, 
            hjust = 0) +
  guides(color=FALSE) +
  theme_classic() +
  labs(x = "ID of electorial district",
       y = "(absolute) prediction error")
  scale_color_manual(values = c("red", "darkgreen"))
  
p_model_error_md_iqr

ggsave(filename = "img/model-error-comp.pdf")
```






# Plotting prediction error against observed values


```{r p-obs-est-err-values, out.width="100%"}
posterior_per_person_best_model <- link(models[["m4a"]])
  
posterior_per_person_best_model %>%  
  as_tibble() %>% 
    summarise_all(median) %>% 
    gather() %>% 
    rename(estimate = value) %>% 
  add_column(area_nr = 1:nrow(.)) %>% 
  full_join(d79) %>%
  mutate(error = abs(estimate - afd_prop),
         top05 = percent_rank(error) >= .95) -> d_short_w_pred_err 


polygon_pos <- data.frame(
  x = c(0, 0.4, 0.4,    0, 0.4, 0, 0 ),
  y = c(0, 0, 0.4,      0, 0.4, 0.4, 0),
  value = c("underestimates", "underestimates", "underestimates", "overestimates", "overestimates", "overestimates", "overestimates")
)
 
d_short_w_pred_err %>%  
  ggplot() +
  aes(x = afd_prop, y = estimate) +
  geom_abline(slope = 1, intercept = 0, color = "grey60") +
  geom_polygon(data = polygon_pos, aes(x = x, y = y, fill = value), alpha = .1) +
  geom_point(aes(color = error,
                 shape = east),
             alpha = .6,
             size = 2) +
  ggrepel::geom_label_repel(aes(label = area_name), data = filter(d_short_w_pred_err, top05 == TRUE)) +
  annotate("text", x = 0.4, y = 0, label = "model understimates", hjust = 1, vjust = 0) +
  annotate("text", x = 0, y = 0.4, label = "model overestimates", hjust = 0, vjust = 1) +
  labs(x = "Observed AfD votes (proportion)",
       y = "Estimated AfD votes (proportion)",
       caption = "n=79 electoral districts; data provided by Bundeswahlleiter 2017") +
  guides(fill = FALSE) +
  theme_classic()

ggsave("img/modelest-vs-obs.pdf", width = 10, height = 5)

```


# Save results


```{r}
save(models, 
     file = "objects/models.Rda")

save(compare_null_models,
     file = "objects/compare_null_models.Rda")

save(compare_reduced_sample,
     file = "objects/compare_reduced_sample.Rda")

save(model_error, 
     file = "objects/model_error.Rda")

save(modell_error_IQR, 
     file = "objects/modell_error_IQR.Rda")


save(model_error_df, 
     file = "objects/model_error_df.RDa")

save(model_error_IQR_df, 
     file = "objects/model_error_IQR_df.RDa")


save(model_error_md_iqr, 
     file = "objects/model_error_md_iqr.RDa")



```

